{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d156bb37-c647-4922-8f88-db436dc37593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98c898b-4327-4575-a6ff-7946c38cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b791de-4ee3-4ed7-b193-44291cea0bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be aware  dirty step to get money  #staylight ...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#sarcasm for #people who don't understand #diy...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@wilw Why do I get the feeling you like games?...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-@TeacherArthurG @rweingarten You probably jus...</td>\n",
       "      <td>figurative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81403</th>\n",
       "      <td>Photo: Image via We Heart It http://t.co/ky8Nf...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81404</th>\n",
       "      <td>I never knew..I better put this out to the Uni...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81405</th>\n",
       "      <td>hey just wanted to say thanks @ puberty for le...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81406</th>\n",
       "      <td>I'm sure coverage like the Fox News Special “T...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>@skeyno16 at u13?! I won't believe it until I ...</td>\n",
       "      <td>sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81408 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets       class\n",
       "0      Be aware  dirty step to get money  #staylight ...  figurative\n",
       "1      #sarcasm for #people who don't understand #diy...  figurative\n",
       "2      @IminworkJeremy @medsingle #DailyMail readers ...  figurative\n",
       "3      @wilw Why do I get the feeling you like games?...  figurative\n",
       "4      -@TeacherArthurG @rweingarten You probably jus...  figurative\n",
       "...                                                  ...         ...\n",
       "81403  Photo: Image via We Heart It http://t.co/ky8Nf...     sarcasm\n",
       "81404  I never knew..I better put this out to the Uni...     sarcasm\n",
       "81405  hey just wanted to say thanks @ puberty for le...     sarcasm\n",
       "81406  I'm sure coverage like the Fox News Special “T...     sarcasm\n",
       "81407  @skeyno16 at u13?! I won't believe it until I ...     sarcasm\n",
       "\n",
       "[81408 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fae7bf7-c341-4ef6-9fde-5c892913ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.sample(n=50000, random_state=42).index).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8776175b-25c4-4bee-8988-34b14d97e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "url_pattern = re.compile(r\"http[s]?://\\S+\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenizer = TweetTokenizer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemma(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    tokens = [token for token in tokenizer.tokenize(text)\n",
    "              if token not in stop_words and not url_pattern.match(token)]\n",
    "\n",
    "    posTags = pos_tag(tokens)\n",
    "\n",
    "    lemmatized = [\n",
    "        lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in posTags\n",
    "    ]\n",
    "\n",
    "    return ' '.join(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5370e308-b0f0-4786-bf27-e17945f7a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['messages'] = df['tweets'].apply(lemma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ebef267-aa45-4b94-a266-7b62a797d230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        iminworkjeremy medsingle dailymail reader sens...\n",
       "1        tune nigezie treat rachel platten fight song m...\n",
       "2        raaachf car ride get listen jess whole time ye...\n",
       "3        ciarakellydoc lunchtiment dont daft dr ciara m...\n",
       "4        dont think tv show could epic mastershowman sh...\n",
       "                               ...                        \n",
       "31403      nothing like someone talk wonderful day sarcasm\n",
       "31404    look like aj brown bad game must overrate smh ...\n",
       "31405    photo image via heart http co ky nf z oi child...\n",
       "31406    sure coverage like fox news special hidden har...\n",
       "31407                       skeyno u believe see p sarcasm\n",
       "Name: messages, Length: 31408, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['messages']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3601b7-bf53-4f58-bf97-c8541e07f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love try help flaw really idea sarcasm nojustno'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['messages'][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b716533-9c02-4bee-919a-6632e2e74d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87e1f3d-0f0d-4600-8c00-6f10c4e5a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tf_idf.fit_transform(df['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b32b4e-82b2-4bc6-b0ef-6bbcc2f94e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c8f985e-68c3-4e29-9d94-cb7b952360eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>class</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@IminworkJeremy @medsingle #DailyMail readers ...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>iminworkjeremy medsingle dailymail reader sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tune in to Nigezie and be treated to Rachel Pl...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>tune nigezie treat rachel platten fight song m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@raaachf for the car ride when I get to listen...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>raaachf car ride get listen jess whole time ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ciarakellydoc @LunchtimeNT dont be daft Dr Ci...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>ciarakellydoc lunchtiment dont daft dr ciara m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I dont think any TV show could be more #Epic t...</td>\n",
       "      <td>figurative</td>\n",
       "      <td>dont think tv show could epic mastershowman sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31403</th>\n",
       "      <td>Nothing like having someone to talk to about y...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>nothing like someone talk wonderful day sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31404</th>\n",
       "      <td>Looks like aj brown is having a bad game... He...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>look like aj brown bad game must overrate smh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31405</th>\n",
       "      <td>Photo: Image via We Heart It http://t.co/ky8Nf...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>photo image via heart http co ky nf z oi child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31406</th>\n",
       "      <td>I'm sure coverage like the Fox News Special “T...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>sure coverage like fox news special hidden har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31407</th>\n",
       "      <td>@skeyno16 at u13?! I won't believe it until I ...</td>\n",
       "      <td>sarcasm</td>\n",
       "      <td>skeyno u believe see p sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31408 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets       class  \\\n",
       "0      @IminworkJeremy @medsingle #DailyMail readers ...  figurative   \n",
       "1      Tune in to Nigezie and be treated to Rachel Pl...  figurative   \n",
       "2      @raaachf for the car ride when I get to listen...  figurative   \n",
       "3      @ciarakellydoc @LunchtimeNT dont be daft Dr Ci...  figurative   \n",
       "4      I dont think any TV show could be more #Epic t...  figurative   \n",
       "...                                                  ...         ...   \n",
       "31403  Nothing like having someone to talk to about y...     sarcasm   \n",
       "31404  Looks like aj brown is having a bad game... He...     sarcasm   \n",
       "31405  Photo: Image via We Heart It http://t.co/ky8Nf...     sarcasm   \n",
       "31406  I'm sure coverage like the Fox News Special “T...     sarcasm   \n",
       "31407  @skeyno16 at u13?! I won't believe it until I ...     sarcasm   \n",
       "\n",
       "                                                messages  \n",
       "0      iminworkjeremy medsingle dailymail reader sens...  \n",
       "1      tune nigezie treat rachel platten fight song m...  \n",
       "2      raaachf car ride get listen jess whole time ye...  \n",
       "3      ciarakellydoc lunchtiment dont daft dr ciara m...  \n",
       "4      dont think tv show could epic mastershowman sh...  \n",
       "...                                                  ...  \n",
       "31403    nothing like someone talk wonderful day sarcasm  \n",
       "31404  look like aj brown bad game must overrate smh ...  \n",
       "31405  photo image via heart http co ky nf z oi child...  \n",
       "31406  sure coverage like fox news special hidden har...  \n",
       "31407                     skeyno u believe see p sarcasm  \n",
       "\n",
       "[31408 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed2332ae-2b5d-4b39-9c80-4acfa438a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9f39f9a-4e5a-4480-90e4-e60cfa920b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['class', 'tweets'])\n",
    "Y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58ee5a8-ab93-49a0-82b2-e617977c5a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ddd191c-868a-4f2c-b271-b5e7b469146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train = tf_idf.fit_transform(X_train['messages'])  \n",
    "X_test = tf_idf.transform(X_test['messages'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3824cae-5e21-4632-8082-3437f52aacd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<24812x48978 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 258624 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa2e40f3-c8bc-4354-a8de-44995018403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "633cd92c-715b-4abd-b8dd-ed8101019268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6076409945421467"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = DecisionTreeClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ae1c8-f5fa-4e16-8433-f72bfb6551e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Step 3: Setup GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1)\n",
    "\n",
    "# Step 4: Fit on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Best parameters and performance\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Step 6: Evaluate on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "joblib.dump(best_model, \"Decision.pkl\")\n",
    "joblib.dump(tf_idf, \"tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ac31e8-39ca-40a4-aa84-936d0498c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],             \n",
    "    'max_depth': [None, 10, 20, 30],       \n",
    "\n",
    "}\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search_random = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_random.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search_random.best_score_)\n",
    "\n",
    "best_model_random = grid_search_random.best_estimator_\n",
    "y_pred = best_model_random.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f23ae6-059b-4b42-b559-02d3aafd0c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf3ad3-da8a-4196-834b-33d39a94ed3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff0b3c-4dd0-45ee-bca3-ddd6148298b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187af3e0-0991-4908-8e24-cb3abc1b10f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f8bde-de62-4cc0-b023-d412096c3a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c17a222-63b9-40c2-a968-004b0d3a71b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
